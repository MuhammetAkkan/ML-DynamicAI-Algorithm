{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SINAV Ã‡ALIÅžMASIDIR",
   "id": "f5377f51eb54b29f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# KOD BLOÄžU #1: KÃ¼tÃ¼phaneleri Ä°Ã§e Aktarma ve Veriyi YÃ¼kleme\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Makine Ã¶ÄŸrenmesi iÃ§in gerekli araÃ§lar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# KullanacaÄŸÄ±mÄ±z 3 farklÄ± tahmin modeli\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# CSV dosyasÄ±ndan mÃ¼ÅŸteri verilerini okuyoruz\n",
    "df = pd.read_csv(\"data/Telco-Customer-Churn.csv\")\n",
    "\n",
    "# KOLON NUMARALAMA SÄ°STEMÄ°\n",
    "def create_column_mapping(dataframe):\n",
    "    \"\"\"\n",
    "    DataFrame'deki tÃ¼m kolonlarÄ± numaralandÄ±rÄ±r.\n",
    "    Returns: {kolon_no: kolon_adÄ±} sÃ¶zlÃ¼ÄŸÃ¼\n",
    "    \"\"\"\n",
    "    return {i+1: col for i, col in enumerate(dataframe.columns)}\n",
    "\n",
    "def get_column_name(col_map, col_no):\n",
    "    \"\"\"Kolon numarasÄ±ndan kolon adÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.\"\"\"\n",
    "    return col_map.get(col_no, None)\n",
    "\n",
    "def get_column_number(col_map, col_name):\n",
    "    \"\"\"Kolon adÄ±ndan kolon numarasÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.\"\"\"\n",
    "    for num, name in col_map.items():\n",
    "        if name == col_name:\n",
    "            return num\n",
    "    return None\n",
    "\n",
    "# Ä°lk kolon haritasÄ±nÄ± oluÅŸtur\n",
    "COLUMN_MAP = create_column_mapping(df)\n",
    "\n",
    "# Kolon listesini yazdÄ±r\n",
    "print(\"=\" * 60)\n",
    "print(\"KOLON NUMARALARI\")\n",
    "print(\"=\" * 60)\n",
    "for num, name in COLUMN_MAP.items():\n",
    "    print(f\"  [{num:2}] {name}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ä°lk 5 satÄ±rÄ± inceliyoruz\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# KOD BLOÄžU #2: Veriyi Ä°nceleme ve KeÅŸfetme (KOLON NUMARALARIYLA)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"VERÄ° SETÄ° ANALÄ°ZÄ°\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Veri boyutu bilgisi\n",
    "print(f\"\\nVeri Boyutu: {df.shape[0]} satÄ±r, {df.shape[1]} kolon\")\n",
    "\n",
    "# Veri tiplerini inceleme\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"KOLON TÄ°P ANALÄ°ZÄ°\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def infer_real_dtype(series):\n",
    "    \"\"\"\n",
    "    Bir kolonun gerÃ§ek veri tipini tahmin eder.\n",
    "    Ä°lk 5 ve son 5 satÄ±rdaki deÄŸerlere bakarak karar verir.\n",
    "    \"\"\"\n",
    "    sample = pd.concat([series.head(5), series.tail(5)]).dropna()\n",
    "\n",
    "    if len(sample) == 0:\n",
    "        return 'unknown'\n",
    "\n",
    "    # SayÄ±ya Ã§evirmeyi dene\n",
    "    try:\n",
    "        numeric_sample = pd.to_numeric(sample.astype(str).str.strip(), errors='coerce')\n",
    "        success_rate = numeric_sample.notna().sum() / len(sample)\n",
    "\n",
    "        if success_rate >= 0.8:\n",
    "            if (numeric_sample.dropna() % 1 == 0).all():\n",
    "                return 'numeric_int'\n",
    "            else:\n",
    "                return 'numeric_float'\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Kategorik mi kontrol et\n",
    "    unique_count = series.nunique()\n",
    "    total_count = len(series)\n",
    "\n",
    "    if unique_count <= max(10, int(total_count * 0.05)):\n",
    "        return 'categorical'\n",
    "\n",
    "    # ID kontrolÃ¼ (tÃ¼m deÄŸerler benzersiz mi?)\n",
    "    if unique_count == total_count:\n",
    "        return 'id'\n",
    "\n",
    "    return 'text'\n",
    "\n",
    "# Analiz sonuÃ§larÄ±nÄ± sakla\n",
    "analysis_results = {}\n",
    "id_columns = []\n",
    "suspicious_columns = []\n",
    "target_column = None\n",
    "\n",
    "print(f\"\\n{'NO':>3} | {'KOLON ADI':<20} | {'MEVCUT TÄ°P':<10} | {'TAHMÄ°N':<15} | {'DURUM':<10}\")\n",
    "\n",
    "for col_no, col_name in COLUMN_MAP.items():\n",
    "    current_dtype = str(df[col_name].dtype)\n",
    "    inferred_type = infer_real_dtype(df[col_name])\n",
    "\n",
    "    # Durumu belirle\n",
    "    status = \"OK\"\n",
    "\n",
    "    # ID sÃ¼tunu mu?\n",
    "    if inferred_type == 'id':\n",
    "        status = \"ID (Silinecek)\"\n",
    "        id_columns.append(col_name)\n",
    "\n",
    "    # Tip uyumsuzluÄŸu var mÄ±?\n",
    "    elif current_dtype == 'object' and inferred_type in ['numeric_int', 'numeric_float']:\n",
    "        status = \"UYUMSUZ\"\n",
    "        suspicious_columns.append(col_name)\n",
    "\n",
    "    # Hedef sÃ¼tun mu? (churn, target vb.)\n",
    "    target_keywords = ['churn', 'target', 'label', 'class', 'outcome']\n",
    "    if any(kw in col_name.lower() for kw in target_keywords):\n",
    "        if df[col_name].nunique() == 2:\n",
    "            status = \"HEDEF\"\n",
    "            target_column = col_name\n",
    "\n",
    "    # SonuÃ§larÄ± kaydet\n",
    "    analysis_results[col_no] = {\n",
    "        'name': col_name,\n",
    "        'current_dtype': current_dtype,\n",
    "        'inferred_type': inferred_type,\n",
    "        'status': status\n",
    "    }\n",
    "\n",
    "    print(f\"[{col_no:2}] | {col_name:<20} | {current_dtype:<10} | {inferred_type:<15} | {status}\")\n",
    "\n",
    "# Ã–zet\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALÄ°Z Ã–ZETÄ°\")\n",
    "\n",
    "if id_columns:\n",
    "    id_nums = [get_column_number(COLUMN_MAP, c) for c in id_columns]\n",
    "    print(f\"ID KolonlarÄ± (silinecek): {id_nums} â†’ {id_columns}\")\n",
    "\n",
    "if suspicious_columns:\n",
    "    susp_nums = [get_column_number(COLUMN_MAP, c) for c in suspicious_columns]\n",
    "    print(f\"Uyumsuz Kolonlar (dÃ¼zeltilecek): {susp_nums} â†’ {suspicious_columns}\")\n",
    "\n",
    "if target_column:\n",
    "    target_num = get_column_number(COLUMN_MAP, target_column)\n",
    "    print(f\"Hedef Kolon: [{target_num}] â†’ {target_column}\")\n",
    "\n",
    "# Uyumsuz kolonlarÄ±n detaylÄ± incelenmesi\n",
    "if suspicious_columns:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"UYUMSUZ KOLON DETAYLARI\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for col_name in suspicious_columns:\n",
    "        col_no = get_column_number(COLUMN_MAP, col_name)\n",
    "        print(f\"\\n[{col_no}] {col_name}:\")\n",
    "        print(f\"    Ä°lk 5 deÄŸer: {df[col_name].head(5).tolist()}\")\n",
    "\n",
    "        # BoÅŸluk karakteri kontrolÃ¼\n",
    "        blank_count = (df[col_name].astype(str).str.strip() == '').sum()\n",
    "        if blank_count > 0:\n",
    "            print(f\"    BoÅŸ deÄŸer sayÄ±sÄ±: {blank_count}\")\n",
    "\n",
    "# Hedef deÄŸiÅŸken grafiÄŸi\n",
    "if target_column:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(f\"HEDEF DEÄžÄ°ÅžKEN DAÄžILIMI: [{get_column_number(COLUMN_MAP, target_column)}] {target_column}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.countplot(x=target_column, data=df)\n",
    "    plt.title(f\"[{get_column_number(COLUMN_MAP, target_column)}] {target_column} DaÄŸÄ±lÄ±mÄ±\")\n",
    "    plt.show()\n",
    "\n",
    "    print(df[target_column].value_counts())\n",
    "\n",
    "# Korelasyon Analizi\n",
    "print(\"\\\\n\" + \"-\" * 80)\n",
    "print(\"KORELASYON ANALÄ°ZÄ°\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Sadece sayÄ±sal kolonlarÄ± seÃ§\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if len(numeric_cols) >= 2:\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "    # Heatmap Ã§iz\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"RdBu_r\",\n",
    "                center=0, vmin=-1, vmax=1, cbar_kws={'label': 'Korelasyon'})\n",
    "    plt.title(\"SayÄ±sal DeÄŸiÅŸkenler ArasÄ± Korelasyon\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Hedef deÄŸiÅŸkenle en yÃ¼ksek korelasyonlarÄ± bul\n",
    "    if target_column and target_column in corr_matrix.columns:\n",
    "        target_corr = corr_matrix[target_column].abs().sort_values(ascending=False)\n",
    "        print(f\"\\\\n[{target_column}] ile en yÃ¼ksek korelasyonlar:\")\n",
    "        for i, (col, val) in enumerate(target_corr.head(6).items()):\n",
    "            if col != target_column:\n",
    "                col_no = get_column_number(COLUMN_MAP, col)\n",
    "                print(f\"    [{col_no}] {col}: {val:.3f}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  Yeteri kadar sayÄ±sal kolon bulunamadÄ±.\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\" * 80)\n"
   ],
   "id": "3c2ad63104fbc67d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# KOD BLOÄžU #3: Veri Temizleme ve HazÄ±rlama (KOLON NUMARALARIYLA)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"VERÄ° TEMÄ°ZLEME\")\n",
    "\n",
    "# 1. ID KOLONLARINI SÄ°L\n",
    "print(\"\\n[1] ID KolonlarÄ±nÄ±n Silinmesi:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if id_columns:\n",
    "    for col_name in id_columns:\n",
    "        col_no = get_column_number(COLUMN_MAP, col_name)\n",
    "        print(f\"    [{col_no}] {col_name} siliniyor...\")\n",
    "    df = df.drop(id_columns, axis=1)\n",
    "    print(f\"    Silinen kolon sayÄ±sÄ±: {len(id_columns)}\")\n",
    "else:\n",
    "    print(\"    ID kolonu bulunamadÄ±\")\n",
    "\n",
    "# Kolon haritasÄ±nÄ± gÃ¼ncelle\n",
    "COLUMN_MAP = create_column_mapping(df)\n",
    "\n",
    "# 2. UYUMSUZ KOLONLARI DÃœZELT\n",
    "print(\"\\n[2] Uyumsuz KolonlarÄ±n DÃ¼zeltilmesi:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if suspicious_columns:\n",
    "    for col_name in suspicious_columns:\n",
    "        if col_name in df.columns:\n",
    "            col_no = get_column_number(COLUMN_MAP, col_name)\n",
    "\n",
    "            # SayÄ±ya Ã§evir\n",
    "            df[col_name] = pd.to_numeric(df[col_name], errors='coerce')\n",
    "\n",
    "            # Eksik deÄŸerleri medyan ile doldur\n",
    "            missing_count = df[col_name].isna().sum()\n",
    "            if missing_count > 0:\n",
    "                median_val = df[col_name].median()\n",
    "                df[col_name] = df[col_name].fillna(median_val)\n",
    "                print(f\"    [{col_no}] {col_name}: {missing_count} eksik deÄŸer medyan ({median_val:.2f}) ile dolduruldu\")\n",
    "            else:\n",
    "                print(f\"    [{col_no}] {col_name}: SayÄ±ya Ã§evrildi, eksik deÄŸer yok\")\n",
    "else:\n",
    "    print(\"    DÃ¼zeltilecek kolon bulunamadÄ±\")\n",
    "\n",
    "# 3. HEDEF DEÄžÄ°ÅžKENÄ° DÃ–NÃœÅžTÃœR\n",
    "print(\"\\n[3] Hedef DeÄŸiÅŸken DÃ¶nÃ¼ÅŸÃ¼mÃ¼:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if target_column and target_column in df.columns:\n",
    "    target_no = get_column_number(COLUMN_MAP, target_column)\n",
    "    print(f\"    Hedef kolon: [{target_no}] {target_column}\")\n",
    "    print(f\"    Mevcut deÄŸerler: {df[target_column].unique().tolist()}\")\n",
    "\n",
    "    # EÄŸer object tipindeyse sayÄ±ya Ã§evir\n",
    "    if df[target_column].dtype == 'object':\n",
    "        unique_vals = df[target_column].unique()\n",
    "        positive_keywords = ['yes', 'true', '1', 'positive', 'churn']\n",
    "\n",
    "        target_map = {}\n",
    "        for val in unique_vals:\n",
    "            if str(val).lower() in positive_keywords:\n",
    "                target_map[val] = 1\n",
    "            else:\n",
    "                target_map[val] = 0\n",
    "\n",
    "        df[target_column] = df[target_column].map(target_map)\n",
    "        print(f\"    DÃ¶nÃ¼ÅŸÃ¼m: {target_map}\")\n",
    "    else:\n",
    "        print(f\"    Zaten sayÄ±sal tipte: {df[target_column].dtype}\")\n",
    "else:\n",
    "    # Hedef kolon bulunamadÄ±ysa Churn'Ã¼ ara\n",
    "    if 'Churn' in df.columns:\n",
    "        target_column = 'Churn'\n",
    "        target_no = get_column_number(COLUMN_MAP, target_column)\n",
    "        print(f\"    VarsayÄ±lan hedef: [{target_no}] {target_column}\")\n",
    "\n",
    "        if df[target_column].dtype == 'object':\n",
    "            target_map = {'Yes': 1, 'No': 0}\n",
    "            df[target_column] = df[target_column].map(target_map)\n",
    "            print(f\"    DÃ¶nÃ¼ÅŸÃ¼m: {target_map}\")\n",
    "\n",
    "# 4. KATEGORÄ°K VERÄ°LERÄ° DÃ–NÃœÅžTÃœR\n",
    "print(\"\\n[4] Kategorik Verilerin DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi (One-Hot Encoding):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Object tipindeki kolonlarÄ± bul (hedef hariÃ§)\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "if target_column in categorical_cols:\n",
    "    categorical_cols.remove(target_column)\n",
    "\n",
    "if categorical_cols:\n",
    "    cat_nums = [get_column_number(COLUMN_MAP, c) for c in categorical_cols]\n",
    "    print(f\"    Kategorik kolonlar: {cat_nums}\")\n",
    "    print(f\"    Kolon adlarÄ±: {categorical_cols}\")\n",
    "\n",
    "    # One-Hot Encoding uygula\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    print(f\"    One-Hot Encoding uygulandÄ±\")\n",
    "    print(f\"    Yeni kolon sayÄ±sÄ±: {len(df.columns)}\")\n",
    "else:\n",
    "    print(\"    Kategorik kolon bulunamadÄ±\")\n",
    "\n",
    "# Kolon haritasÄ±nÄ± gÃ¼ncelle\n",
    "COLUMN_MAP = create_column_mapping(df)\n",
    "\n",
    "# 5. Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ° (Feature Engineering)\n",
    "print(\"\\n[5] Ã–zellik MÃ¼hendisliÄŸi:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "new_features_created = False\n",
    "\n",
    "# Tenure varsa yÄ±l gruplarÄ± oluÅŸtur\n",
    "if 'tenure' in df.columns:\n",
    "    print(\"    â€¢ Tenure YÄ±l GruplarÄ± oluÅŸturuluyor...\")\n",
    "\n",
    "    def tenure_to_year_group(months):\n",
    "        if months <= 12: return \"0-1_Yil\"\n",
    "        elif months <= 24: return \"1-2_Yil\"\n",
    "        elif months <= 36: return \"2-3_Yil\"\n",
    "        elif months <= 48: return \"3-4_Yil\"\n",
    "        else: return \"4+_Yil\"\n",
    "\n",
    "    df['NEW_TenureYear'] = df['tenure'].apply(tenure_to_year_group)\n",
    "    print(f\"      OluÅŸturuldu: NEW_TenureYear\")\n",
    "    print(f\"      DaÄŸÄ±lÄ±m: {dict(df['NEW_TenureYear'].value_counts())}\")\n",
    "    new_features_created = True\n",
    "\n",
    "# Servis sayÄ±sÄ± hesapla\n",
    "service_cols = [col for col in df.columns if any(s in col.lower()\n",
    "                for s in ['phone', 'internet', 'security', 'backup',\n",
    "                         'protection', 'support', 'streaming'])]\n",
    "\n",
    "if service_cols:\n",
    "    print(\"    â€¢ Toplam Servis SayÄ±sÄ± hesaplanÄ±yor...\")\n",
    "    # Her kolon iÃ§in 'Yes' veya 1 iÃ§erip iÃ§ermediÄŸini kontrol et\n",
    "    df['NEW_TotalServices'] = df[service_cols].apply(\n",
    "        lambda row: sum(1 for val in row if str(val).lower() in ['yes', '1', 'true']),\n",
    "        axis=1\n",
    "    )\n",
    "    print(f\"      OluÅŸturuldu: NEW_TotalServices\")\n",
    "    print(f\"      Ortalama servis: {df['NEW_TotalServices'].mean():.2f}\")\n",
    "    print(f\"      Min: {df['NEW_TotalServices'].min()}, Max: {df['NEW_TotalServices'].max()}\")\n",
    "    new_features_created = True\n",
    "\n",
    "if new_features_created:\n",
    "    # Yeni kategorik Ã¶zellikleri encode et\n",
    "    new_cat_cols = [col for col in df.columns if col.startswith('NEW_') and df[col].dtype == 'object']\n",
    "    if new_cat_cols:\n",
    "        df = pd.get_dummies(df, columns=new_cat_cols, drop_first=True)\n",
    "        print(f\"    â€¢ Yeni kategorik Ã¶zellikler encode edildi\")\n",
    "\n",
    "    # Kolon haritasÄ±nÄ± gÃ¼ncelle\n",
    "    COLUMN_MAP = create_column_mapping(df)\n",
    "    print(f\"Toplam {len([c for c in df.columns if c.startswith('NEW_')])} yeni Ã¶zellik eklendi\")\n",
    "else:\n",
    "    print(\"Yeni Ã¶zellik oluÅŸturulamadÄ± (gerekli kolonlar bulunamadÄ±)\")\n",
    "\n",
    "# Son durum\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEMÄ°ZLEME SONRASI VERÄ°\")\n",
    "print(f\"Boyut: {df.shape[0]} satÄ±r, {df.shape[1]} kolon\")\n",
    "print(f\"\\nÄ°lk 5 kolon:\")\n",
    "for i, (num, name) in enumerate(COLUMN_MAP.items()):\n",
    "    if i >= 5:\n",
    "        print(f\"    ... ve {len(COLUMN_MAP) - 5} kolon daha\")\n",
    "        break\n",
    "    print(f\"    [{num}] {name}\")\n",
    "\n",
    "df.head()"
   ],
   "id": "8b8182cdb79181ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# KOD BLOÄžU #4: Veriyi EÄŸitim ve Test Olarak AyÄ±rma (KOLON NUMARALARIYLA)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"VERÄ° BÃ–LME VE Ã–LÃ‡EKLENDÄ°RME\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. HEDEF KOLONU BUL\n",
    "print(\"\\n[1] Hedef Kolon:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# target_column deÄŸiÅŸkeni Kod BloÄŸu #2'den geliyor\n",
    "if target_column and target_column in df.columns:\n",
    "    target_no = get_column_number(COLUMN_MAP, target_column)\n",
    "    print(f\"    Hedef: [{target_no}] {target_column}\")\n",
    "else:\n",
    "    # Churn'Ã¼ ara\n",
    "    target_column = 'Churn'\n",
    "    target_no = get_column_number(COLUMN_MAP, target_column)\n",
    "    print(f\"    VarsayÄ±lan hedef: [{target_no}] {target_column}\")\n",
    "\n",
    "# 2. X VE Y AYIR\n",
    "print(\"\\n[2] Ã–zellik (X) ve Hedef (y) AyrÄ±mÄ±:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "y = df[target_column]\n",
    "X = df.drop(target_column, axis=1)\n",
    "\n",
    "print(f\"    Hedef (y): [{target_no}] {target_column}\")\n",
    "print(f\"    Ã–zellik (X): {X.shape[1]} kolon\")\n",
    "print(f\"    Hedef daÄŸÄ±lÄ±mÄ±: 0 â†’ {(y == 0).sum()}, 1 â†’ {(y == 1).sum()}\")\n",
    "\n",
    "# 3. DENGESÄ°ZLÄ°K KONTROLÃœ\n",
    "print(\"\\n[3] Dengesizlik KontrolÃ¼:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "class_ratio = y.value_counts(normalize=True)\n",
    "minority_ratio = class_ratio.min()\n",
    "\n",
    "if minority_ratio < 0.3:\n",
    "    print(f\"    Dengesiz veri tespit edildi!\")\n",
    "    print(f\"    AzÄ±nlÄ±k sÄ±nÄ±f oranÄ±: {minority_ratio:.1%}\")\n",
    "    print(f\"    stratify=y kullanÄ±lacak\")\n",
    "else:\n",
    "    print(f\"    Veri dengeli (azÄ±nlÄ±k oranÄ±: {minority_ratio:.1%})\")\n",
    "\n",
    "# 4. EÄžÄ°TÄ°M/TEST BÃ–LME\n",
    "print(\"\\n[4] EÄŸitim/Test BÃ¶lme:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"    EÄŸitim seti: {len(X_train)} satÄ±r (%80)\")\n",
    "print(f\"    Test seti: {len(X_test)} satÄ±r (%20)\")\n",
    "\n",
    "# 5. Ã–LÃ‡EKLENDÄ°RME\n",
    "print(\"\\n[5] Ã–zellik Ã–lÃ§eklendirme (StandardScaler):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"    TÃ¼m Ã¶zellikler Ã¶lÃ§eklendirildi\")\n",
    "print(f\"    Ortalama: 0, Standart Sapma: 1\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ],
   "id": "68cd58013517d62f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# KOD BLOÄžU #5: Model 1 - Logistic Regression\n",
    "# En basit sÄ±nÄ±flandÄ±rma modeli\n",
    "# Her Ã¶zelliÄŸe aÄŸÄ±rlÄ±k verir, aÄŸÄ±rlÄ±klÄ± toplam 0.5'ten bÃ¼yÃ¼kse â†’ Churn=1\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION\")\n",
    "\n",
    "# Modeli oluÅŸtur ve eÄŸit\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin yap\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "# SonuÃ§larÄ± kaydet\n",
    "log_accuracy = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "print(f\"\\nAccuracy: {log_accuracy:.4f} ({log_accuracy*100:.2f}%)\")\n",
    "print(\"\\nDetaylÄ± Rapor:\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n",
    "# Hata Matrisi\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_log), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Logistic Regression - Hata Matrisi\")\n",
    "plt.ylabel('GerÃ§ek')\n",
    "plt.xlabel('Tahmin')\n",
    "plt.show()"
   ],
   "id": "3d66f07a0c0e27cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# KOD BLOÄžU #6: Model 2 - Random Forest\n",
    "# Birden fazla karar aÄŸacÄ± oluÅŸturur (100 aÄŸaÃ§)\n",
    "# TÃ¼m aÄŸaÃ§lar oy kullanÄ±r, Ã§oÄŸunluk kazanÄ±r\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "\n",
    "# Modeli oluÅŸtur ve eÄŸit\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin yap\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# SonuÃ§larÄ± kaydet\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\nAccuracy: {rf_accuracy:.4f} ({rf_accuracy*100:.2f}%)\")\n",
    "print(\"\\nDetaylÄ± Rapor:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Hata Matrisi\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"Random Forest - Hata Matrisi\")\n",
    "plt.ylabel('GerÃ§ek')\n",
    "plt.xlabel('Tahmin')\n",
    "plt.show()"
   ],
   "id": "54b171abf66a62a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# KOD BLOÄžU #7: Model 3 - XGBoost\n",
    "# Gradient boosting tekniÄŸi kullanÄ±r\n",
    "# Her yeni aÄŸaÃ§, Ã¶nceki aÄŸacÄ±n hatalarÄ±nÄ± dÃ¼zeltmeye Ã§alÄ±ÅŸÄ±r\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL 3: XGBOOST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Modeli oluÅŸtur ve eÄŸit\n",
    "# logloss: Modelin tahminlerindeki gÃ¼veni de Ã¶lÃ§er\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin yap\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# SonuÃ§larÄ± kaydet\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"\\nAccuracy: {xgb_accuracy:.4f} ({xgb_accuracy*100:.2f}%)\")\n",
    "print(\"\\nDetaylÄ± Rapor:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# Hata Matrisi\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='d', cmap='Oranges')\n",
    "plt.title(\"XGBoost - Hata Matrisi\")\n",
    "plt.ylabel('GerÃ§ek')\n",
    "plt.xlabel('Tahmin')\n",
    "plt.show()"
   ],
   "id": "66b7b8945262c67f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# KOD BLOÄžU #8: Model KarÅŸÄ±laÅŸtÄ±rma ve SonuÃ§\n",
    "print(\"=\" * 80)\n",
    "print(\"GELÄ°ÅžMÄ°Åž MODEL KARÅžILAÅžTIRMA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# TÃ¼m metrikleri hesapla\n",
    "results = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Accuracy': [\n",
    "        log_accuracy,\n",
    "        rf_accuracy,\n",
    "        xgb_accuracy\n",
    "    ],\n",
    "    'F1 Score': [\n",
    "        f1_score(y_test, y_pred_log),\n",
    "        f1_score(y_test, y_pred_rf),\n",
    "        f1_score(y_test, y_pred_xgb)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, y_pred_log),\n",
    "        recall_score(y_test, y_pred_rf),\n",
    "        recall_score(y_test, y_pred_xgb)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_test, y_pred_log),\n",
    "        precision_score(y_test, y_pred_rf),\n",
    "        precision_score(y_test, y_pred_xgb)\n",
    "    ]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nðŸ“Š DETAYLI PERFORMANS TABLOSU:\")\n",
    "print(\"-\" * 90)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# En iyi modeli F1 Score'a gÃ¶re seÃ§ (daha dengeli metrik)\n",
    "best_idx = results_df['F1 Score'].idxmax()\n",
    "best_model_name = results_df.iloc[best_idx]['Model']\n",
    "best_f1 = results_df.iloc[best_idx]['F1 Score']\n",
    "best_accuracy = results_df.iloc[best_idx]['Accuracy']\n",
    "best_recall = results_df.iloc[best_idx]['Recall']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(f\"ðŸ† EN Ä°YÄ° MODEL: {best_model_name}\")\n",
    "print(f\"   Accuracy:  {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "print(f\"   F1 Score:  {best_f1:.4f} (Precision ve Recall dengesi)\")\n",
    "print(f\"   Recall:    {best_recall:.4f} (Churn'leri yakalama oranÄ±)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# GÃ¶rsel karÅŸÄ±laÅŸtÄ±rma - TÃ¼m metrikler\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Model KarÅŸÄ±laÅŸtÄ±rmasÄ± - TÃ¼m Metrikler', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['Accuracy', 'F1 Score', 'Recall', 'Precision']\n",
    "colors_palette = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12']\n",
    "\n",
    "for idx, (ax, metric) in enumerate(zip(axes.flat, metrics)):\n",
    "    sorted_df = results_df.sort_values(metric, ascending=True)\n",
    "    colors = [colors_palette[idx] if m != best_model_name else '#9b59b6' for m in sorted_df['Model']]\n",
    "\n",
    "    bars = ax.barh(sorted_df['Model'], sorted_df[metric], color=colors)\n",
    "    ax.set_xlabel(metric, fontweight='bold')\n",
    "    ax.set_title(f'{metric} KarÅŸÄ±laÅŸtÄ±rmasÄ±')\n",
    "\n",
    "    # DeÄŸerleri gÃ¶ster\n",
    "    for bar, val in zip(bars, sorted_df[metric]):\n",
    "        ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
    "                f'{val:.4f}', va='center', fontsize=9)\n",
    "\n",
    "    # X ekseni sÄ±nÄ±rlarÄ±nÄ± ayarla\n",
    "    min_val = sorted_df[metric].min()\n",
    "    max_val = sorted_df[metric].max()\n",
    "    ax.set_xlim(min_val - 0.05, max_val + 0.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSONUÃ‡:\")\n",
    "print(f\"Bu veri seti iÃ§in {best_model_name} modeli en iyi performansÄ± gÃ¶sterdi.\")\n",
    "print(f\"Model, test verisinde {best_accuracy*100:.2f}% doÄŸruluk ve {best_f1:.4f} F1 Score'a ulaÅŸtÄ±.\")\n",
    "print(f\"Recall: {best_recall:.4f} - Model churn olacak mÃ¼ÅŸterilerin %{best_recall*100:.1f}'ini yakalayabiliyor.\")\n",
    "\n"
   ],
   "id": "e40ab4eae6c2871e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
